---
title: "Developer Guide"
description: "SDK Integration for RealTimeX Local Apps"
---

import { Callout, Tabs } from 'nextra/components'

# Local Apps Developer Guide

This guide covers how to integrate your applications with RealTimeX. Depending on your project requirements, you can choose between two operating modes.


## Prerequisites

Regardless of the mode you choose, you must first configure your Local App in the RealTimeX Main App:

1. Open **RealTimeX** â†’ **Settings** â†’ **Local Apps**
2. Create or configure your Local App
3. Enter Supabase **URL** and **Anon Key**
4. For **Compatible Mode**, click **Login to Supabase** â†’ **Auto-Setup Schema**.

<Callout type="info">
If using Compatible Mode, schema setup is handled entirely by the Main App. **No manual SQL required.**
</Callout>

## Installation

<Tabs items={['TypeScript', 'Python']}>
  <Tabs.Tab>
    ```bash
    npm install @realtimex/sdk
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    pip install realtimex-sdk
    ```
  </Tabs.Tab>
</Tabs>

## Demo Examples

Check out our complete demo applications showcasing all SDK features:

ðŸ‘‰ **[GitHub: local-app-examples](https://github.com/therealtimex/local-app-examples)**

| Example | Language | Description |
|---------|----------|-------------|
| `nodejs-app` | TypeScript + Express | Full-featured demo with TailwindCSS UI |
| `python-app` | Python + NiceGUI | Interactive demo with real-time UI |

## Quick Start

When you start your Local App from the RealTimeX Main App, environment variables `RTX_APP_ID` and `RTX_APP_NAME` are automatically set. The SDK auto-detects these.

<Tabs items={['TypeScript', 'Python']}>
  <Tabs.Tab>
    ```typescript
    import express from 'express';
    import { RealtimeXSDK } from '@realtimex/sdk';

    const app = express();
    const sdk = new RealtimeXSDK({
        permissions: [
            'api.agents',       // List agents
            'api.workspaces',   // List workspaces
            'api.threads',      // List threads
            'webhook.trigger',  // Trigger agents
            'activities.read',  // Read activities
            'activities.write', // Write activities
            'llm.chat',         // Chat completion
            'llm.embed',        // Generate embeddings
            'vectors.read',     // Query vectors
            'vectors.write',    // Store vectors
        ],
    });
    

    // Get available port (auto-detects or finds free port if conflict)
    const port = await sdk.port.getPort();

    // Insert activity
    const activity = await sdk.activities.insert({
      type: 'new_lead',
      email: 'user@example.com',
    });

    // Trigger agent
    await sdk.webhook.triggerAgent({
      raw_data: activity,
      auto_run: true,
      agent_name: 'processor',
      workspace_slug: 'sales',
      thread_slug: 'general',
    });

    app.listen(port, () => console.log(`Running on port ${port}`));
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```python
    from nicegui import ui
    from realtimex_sdk import RealtimeXSDK

    sdk = RealtimeXSDK(config=SDKConfig(
        permissions=[
            'api.agents',       # List agents
            'api.workspaces',   # List workspaces
            'api.threads',      # List threads
            'webhook.trigger',  # Trigger agents
            'activities.read',  # Read activities
            'activities.write', # Write activities
            'llm.chat',         # Chat completion
            'llm.embed',        # Generate embeddings
            'vectors.read',     # Query vectors
            'vectors.write',    # Store vectors
        ]
    ))

    # Get available port (auto-detects or finds free port if conflict)
    port = sdk.port.get_port()

    # Insert activity
    activity = await sdk.activities.insert({
        "type": "new_lead",
        "email": "user@example.com"
    })

    # Trigger agent
    await sdk.webhook.trigger_agent(
        raw_data=activity,
        auto_run=True,
        agent_name="processor",
        workspace_slug="sales",
        thread_slug="general",
    )

    ui.run(port=port)
    ```
  </Tabs.Tab>
</Tabs>

---

## SDK Features

### Activities CRUD

Manage your `activities` table directly through the SDK without needing direct database access. Any data changes (INSERT, UPDATE, or DELETE) will automatically create a new calendar event. If Automation Agent Handlers are configured, they will also trigger an automated agent task.

<Tabs items={['TypeScript', 'Python']}>
  <Tabs.Tab>
    ```typescript
    // Insert new activity
    const activity = await sdk.activities.insert({
      type: 'order',
      amount: 100
    });

    // List activities with filters
    const pending = await sdk.activities.list({
      status: 'pending',
      limit: 10
    });

    // Get single activity
    const item = await sdk.activities.get('activity-uuid');

    // Update activity
    await sdk.activities.update('activity-uuid', {
      status: 'processed'
    });

    // Delete activity
    await sdk.activities.delete('activity-uuid');
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```python
    # Insert new activity
    activity = await sdk.activities.insert({
        "type": "order",
        "amount": 100
    })

    # List activities with filters
    pending = await sdk.activities.list(
        status="pending",
        limit=10
    )

    # Get single activity
    item = await sdk.activities.get("activity-uuid")

    # Update activity
    await sdk.activities.update("activity-uuid", {
        "status": "processed"
    })

    # Delete activity
    await sdk.activities.delete("activity-uuid")
    ```
  </Tabs.Tab>
</Tabs>

### Webhook & Agent Triggering

Trigger AI Agents to process data either manually or automatically.

<Tabs items={['TypeScript', 'Python']}>
  <Tabs.Tab>
    ```typescript
    // Manual Mode (Default) - Creates calendar event for review
    await sdk.webhook.triggerAgent({
      raw_data: { email: 'user@example.com' },
    });

    // Auto-run Mode - Triggers agent immediately
    await sdk.webhook.triggerAgent({
      raw_data: activity,
      auto_run: true,
      agent_name: 'pdf-processor',
      workspace_slug: 'operations',
      thread_slug: 'general', // or "create_new" to create new thread
      prompt: 'Summarize this file' // Optional
    });
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```python
    # Manual Mode (Default)
    await sdk.webhook.trigger_agent(
        raw_data={"email": "user@example.com"}
    )

    # Auto-run Mode
    await sdk.webhook.trigger_agent(
        raw_data=activity,
        auto_run=True,
        agent_name="pdf-processor",
        workspace_slug="operations",
        thread_slug="general", # or "create_new" to create new thread
        prompt="Summarize this file"
    )
    ```
  </Tabs.Tab>
</Tabs>

### Public Metadata API

Access RealTimeX system metadata like available agents and workspaces.

<Tabs items={['TypeScript', 'Python']}>
  <Tabs.Tab>
    ```typescript
    const agents = await sdk.api.getAgents();
    const workspaces = await sdk.api.getWorkspaces();
    const threads = await sdk.api.getThreads('workspace-slug');
    const taskStatus = await sdk.api.getTask('task-uuid');
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```python
    agents = await sdk.api.get_agents()
    workspaces = await sdk.api.get_workspaces()
    threads = await sdk.api.get_threads("workspace-slug")
    task_status = await sdk.api.get_task("task-uuid")
    ```
  </Tabs.Tab>
</Tabs>

---

### Port Management

The SDK includes automatic port management to prevent conflicts when running multiple Local Apps simultaneously.

<Tabs items={['TypeScript', 'Python']}>
  <Tabs.Tab>
    ```typescript
    // Get an available port (auto-detects from RTX_PORT or finds free port)
    const port = await sdk.port.getPort();
    app.listen(port);
    
    // Or use individual methods
    const suggested = sdk.port.getSuggestedPort(); // RTX_PORT env or 8080
    const available = await sdk.port.isPortAvailable(3000);
    const freePort = await sdk.port.findAvailablePort(8080);
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```python
    # Get an available port (auto-detects from RTX_PORT or finds free port)
    port = sdk.port.get_port()
    ui.run(port=port)  # NiceGUI
    
    # Or use individual methods
    suggested = sdk.port.get_suggested_port()  # RTX_PORT env or 8080
    available = sdk.port.is_port_available(3000)
    free_port = sdk.port.find_available_port(8080)
    ```
  </Tabs.Tab>
</Tabs>

<Callout type="info">
**How it works**: When launched from RealTimeX, your app receives an `RTX_PORT` environment variable with the configured port. The SDK uses this as the starting point and automatically finds the next available port if it's occupied.
</Callout>

---

### LLM Proxy & Vector Store

The SDK provides access to RealtimeX's LLM capabilities without needing to manage API keys directly. Perfect for building RAG (Retrieval-Augmented Generation) applications.

**Required Permissions:**
```typescript
const sdk = new RealtimeXSDK({
  permissions: ['llm.chat', 'llm.embed', 'llm.providers', 'vectors.read', 'vectors.write']
});
```

#### List Available Models

<Tabs items={['TypeScript', 'Python']}>
  <Tabs.Tab>
    ```typescript
    const { llm, embedding } = await sdk.llm.getProviders();
    console.log('Chat models:', llm[0].models);
    console.log('Embedding models:', embedding[0].models);
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```python
    providers = await sdk.llm.get_providers()
    print(f"Chat models: {providers.llm[0].models}")
    print(f"Embedding models: {providers.embedding[0].models}")
    ```
  </Tabs.Tab>
</Tabs>

#### Chat Completion

<Tabs items={['TypeScript', 'Python']}>
  <Tabs.Tab>
    ```typescript
    // Sync chat
    const response = await sdk.llm.chat([
      { role: 'system', content: 'You are a helpful assistant.' },
      { role: 'user', content: 'What is RealtimeX?' }
    ], { model: 'gpt-4o', temperature: 0.7 });
    console.log(response.response?.content);

    // Streaming chat
    for await (const chunk of sdk.llm.chatStream(messages)) {
      process.stdout.write(chunk.textResponse || '');
    }
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```python
    from realtimex_sdk import ChatMessage, ChatOptions

    # Sync chat
    response = await sdk.llm.chat(
        messages=[
            ChatMessage(role="system", content="You are a helpful assistant."),
            ChatMessage(role="user", content="What is RealtimeX?")
        ],
        options=ChatOptions(model="gpt-4o", temperature=0.7)
    )
    print(response.content)

    # Streaming chat
    async for chunk in sdk.llm.chat_stream(messages):
        print(chunk.text, end="", flush=True)
    ```
  </Tabs.Tab>
</Tabs>

#### Generate Embeddings

<Tabs items={['TypeScript', 'Python']}>
  <Tabs.Tab>
    ```typescript
    const { embeddings, dimensions } = await sdk.llm.embed(['Hello world', 'Goodbye']);
    console.log(`Generated ${embeddings.length} vectors of ${dimensions} dimensions`);
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```python
    result = await sdk.llm.embed(["Hello world", "Goodbye"])
    print(f"Generated {len(result.embeddings)} vectors of {result.dimensions} dimensions")
    ```
  </Tabs.Tab>
</Tabs>

#### Vector Store (RAG)

Store and search vectors for building knowledge bases:

<Tabs items={['TypeScript', 'Python']}>
  <Tabs.Tab>
    ```typescript
    // Store vectors with metadata
    await sdk.llm.vectors.upsert([
      { 
        id: 'chunk-1', 
        vector: embeddings[0], 
        metadata: { text: 'Original text...', documentId: 'doc-1' } 
      }
    ], { workspaceId: 'knowledge-base' });

    // Search similar vectors
    const results = await sdk.llm.vectors.query(queryVector, {
      topK: 5,
      workspaceId: 'knowledge-base'
    });

    // List all workspaces for this app
    const { workspaces } = await sdk.llm.vectors.listWorkspaces();
    console.log('Workspaces:', workspaces); // ['knowledge-base', 'default', ...]

    // Delete all vectors in workspace
    await sdk.llm.vectors.delete({ deleteAll: true, workspaceId: 'knowledge-base' });
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```python
    from realtimex_sdk import VectorRecord

    # Store vectors with metadata
    await sdk.llm.vectors.upsert(
        vectors=[
            VectorRecord(
                id="chunk-1",
                vector=embeddings[0],
                metadata={"text": "Original text...", "documentId": "doc-1"}
            )
        ],
        workspace_id="knowledge-base"
    )

    # Search similar vectors
    results = await sdk.llm.vectors.query(
        vector=query_vector,
        top_k=5,
        workspace_id="knowledge-base"
    )

    # List all workspaces for this app
    res = await sdk.llm.vectors.list_workspaces()
    print(f"Workspaces: {res.workspaces}") # ['knowledge-base', 'default', ...]

    # Delete all vectors in workspace
    await sdk.llm.vectors.delete(delete_all=True, workspace_id="knowledge-base")
    ```
  </Tabs.Tab>
</Tabs>

#### High-Level Helpers (Recommended)

For common RAG patterns, use these helpers that combine embedding + storage/search:

<Tabs items={['TypeScript', 'Python']}>
  <Tabs.Tab>
    ```typescript
    // Embed and store in one call (text â†’ vectors â†’ storage)
    await sdk.llm.embedAndStore(
      ['Document chunk 1', 'Document chunk 2'],
      { documentId: 'doc-123', workspaceId: 'knowledge-base' }
    );

    // Semantic search (query â†’ embed â†’ search)
    const results = await sdk.llm.search('What is RealtimeX?', {
      topK: 5,
      workspaceId: 'knowledge-base',
      documentId: 'doc-123' // Optional: filter by document
    });
    
    // Use results for RAG
    const context = results.map(r => r.metadata.text).join('\n');
    const response = await sdk.llm.chat([
      { role: 'system', content: `Context:\n${context}` },
      { role: 'user', content: 'What is RealtimeX?' }
    ]);
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```python
    # Embed and store in one call (text â†’ vectors â†’ storage)
    await sdk.llm.embed_and_store(
        texts=["Document chunk 1", "Document chunk 2"],
        document_id="doc-123",
        workspace_id="knowledge-base"
    )

    # Semantic search (query â†’ embed â†’ search)
    results = await sdk.llm.search(
        query="What is RealtimeX?",
        top_k=5,
        workspace_id="knowledge-base",
        document_id="doc-123"  # Optional: filter by document
    )
    
    # Use results for RAG
    context = "\n".join([r["metadata"]["text"] for r in results])
    response = await sdk.llm.chat(
        messages=[
            ChatMessage(role="system", content=f"Context:\n{context}"),
            ChatMessage(role="user", content="What is RealtimeX?")
        ]
    )
    ```
  </Tabs.Tab>
</Tabs>

<Callout type="tip">
**Isolation vs Filtering:**
- **`workspaceId`**: Creates physical namespace (`sdk_{appId}_{wsId}`) - data completely isolated
- **`documentId`**: Metadata tag, filtered after search - logical grouping within workspace
</Callout>

---

## REST API Access

If you are not using one of our official SDKs, you can communicate with RealTimeX directly via our REST API.

ðŸ‘‰ [View REST API Reference](/local-apps/api-reference)
