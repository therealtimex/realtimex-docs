---
title: "Overview"
description: "Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data."
---

import { FeatureCard } from "@/components/FeatureCard";
import { Callout } from "nextra/components";

# Large Language Models

<Callout type="info" emoji="ðŸ’¡">
  **Tip:** Multi-modal models (text-to-text & image-to-text) are supported for both System and Workspace LLMs.
</Callout>

Large language models (LLMs) are advanced AI systems that understand and generate human language by processing vast amounts of data.  
RealTimeX gives you the flexibility to mix and match LLMsâ€”local or cloud, general-purpose or specializedâ€”to fit every workflow.

## Types of LLMs in RealTimeX

### System LLM
The default LLM RealTimeX will use for all workspaces and agents unless a more specific LLM is configured.

### Workspace LLM
Assign workspace-specific LLMs to override the system LLM for individual teams or projects. This allows each workspace to use its own provider and model.

### Agent LLM
RealTimeX supports agent-specific LLMs. Some models are better for tool calling or agent orchestration.  
Assign dedicated models for AI agents where advanced features or reliability is critical.

## Supported LLM Providers

You can switch your provider, model, or configuration at any time with no downtime.  
Connect to both local and cloud LLMs simultaneouslyâ€”even mix and match as you go!

### Local Language Model Providers

<div style={{
  display: "grid",
  gridTemplateColumns: "repeat(auto-fit, minmax(230px, 1fr))",
  gap: "1rem",
  margin: "1.2rem 0"
}}>
  <FeatureCard title="Built-in (default)" href="./setup/llm-configuration/local/built-in">
    <img
      src="/images/ai-providers/realtimex.png"
      alt="RealTimeX Built-in"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Default, private, high-performance LLM engineâ€”no setup needed.</div>
  </FeatureCard>
  <FeatureCard title="Ollama" href="./setup/llm-configuration/local/ollama">
    <img
      src="/images/ai-providers/ollama.svg"
      alt="Ollama"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Modern local LLM runner, supporting a wide range of open models.</div>
  </FeatureCard>
  <FeatureCard title="LM Studio" href="./setup/llm-configuration/local/lmstudio">
    <img
      src="/images/ai-providers/lmstudio.svg"
      alt="LM Studio"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Easy desktop app for local LLM inference and management.</div>
  </FeatureCard>
  <FeatureCard title="Local AI" href="./setup/llm-configuration/local/localai">
    <img
      src="/images/ai-providers/localai.png"
      alt="Local AI"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Open source, extensible local inference backend for LLMs.</div>
  </FeatureCard>
  <FeatureCard title="KoboldCPP" href="./setup/llm-configuration/local/kobaldcpp">
    <img
      src="/images/ai-providers/koboldcpp.png"
      alt="KoboldCPP"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Run GGUF models on your own hardware, locally.</div>
  </FeatureCard>
</div>

### Cloud Language Model Providers

<div style={{
  display: "grid",
  gridTemplateColumns: "repeat(auto-fit, minmax(230px, 1fr))",
  gap: "1rem",
  margin: "1.2rem 0"
}}>
  <FeatureCard title="OpenAI" href="./setup/llm-configuration/cloud/openai">
    <img
      src="/images/ai-providers/openai.svg"
      alt="OpenAI"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>GPT-4o, GPT-4, GPT-3.5, and moreâ€”state-of-the-art performance.</div>
  </FeatureCard>
  <FeatureCard title="Azure OpenAI" href="./setup/llm-configuration/cloud/azure-openai">
    <img
      src="/images/ai-providers/azure.svg"
      alt="Azure OpenAI"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Enterprise-grade LLMs managed by Microsoft Azure.</div>
  </FeatureCard>
  <FeatureCard title="Anthropic" href="./setup/llm-configuration/cloud/anthropic">
    <img
      src="/images/ai-providers/anthropic.svg"
      alt="Anthropic"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Claude 3, Opus, and the full Anthropic model family.</div>
  </FeatureCard>
  <FeatureCard title="Cohere" href="./setup/llm-configuration/cloud/cohere">
    <img
      src="/images/ai-providers/cohere-color.svg"
      alt="Cohere"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Enterprise language and embedding models.</div>
  </FeatureCard>
  <FeatureCard title="Google Gemini Pro" href="./setup/llm-configuration/cloud/google-gemini">
    <img
      src="/images/ai-providers/gemini-color.svg"
      alt="Gemini"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Googleâ€™s latest multi-modal LLM (Gemini series).</div>
  </FeatureCard>
  <FeatureCard title="Hugging Face" href="./setup/llm-configuration/cloud/huggingface">
    <img
      src="/images/ai-providers/huggingface-color.svg"
      alt="Hugging Face"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Access any model from the Hugging Face Hub.</div>
  </FeatureCard>
  <FeatureCard title="Together AI" href="./setup/llm-configuration/cloud/together-ai">
    <img
      src="/images/ai-providers/together-color.svg"
      alt="Together AI"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Fast, multi-model LLM provider with open APIs.</div>
  </FeatureCard>
  <FeatureCard title="OpenRouter" href="/setup/llm-configuration/cloud/openrouter">
    <img
      src="/images/ai-providers/openrouter.svg"
      alt="OpenRouter"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Unified API for many top LLMs.</div>
  </FeatureCard>
  <FeatureCard title="Perplexity AI" href="./setup/llm-configuration/cloud/perplexity-ai">
    <img
      src="/images/ai-providers/perplexity.svg"
      alt="Perplexity AI"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Conversational search and generative AI.</div>
  </FeatureCard>
  <FeatureCard title="Mistral API" href="./setup/llm-configuration/cloud/mistral-ai">
    <img
      src="/images/ai-providers/mistral-color.svg"
      alt="Mistral API"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Fast, powerful open models (Mistral, Mixtral, etc).</div>
  </FeatureCard>
  <FeatureCard title="Groq" href="./setup/llm-configuration/cloud/groq">
    <img
      src="/images/ai-providers/groq.svg"
      alt="Groq"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Ultra-fast inference for popular LLMs.</div>
  </FeatureCard>
  <FeatureCard title="OpenAI (generic)" href="./setup/llm-configuration/cloud/openai-generic">
    <img
      src="/images/ai-providers/openai.svg"
      alt="OpenAI (generic)"
      height={38}
      style={{
        display: "block",
        marginBottom: 8,
        maxHeight: 38,
        width: "auto",
        maxWidth: 80,
        objectFit: "contain"
      }}
    />
    <div>Generic OpenAI-compatible API for custom setups.</div>
  </FeatureCard>
</div>
